# =============================================================================
# SMARTATTEND SYSTEM ALERTS
# Critical alerts for production monitoring
# =============================================================================

groups:
  # =============================================================================
  # SYSTEM LEVEL ALERTS
  # =============================================================================

  - name: system.rules
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: 100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for more than 5 minutes. Current value: {{ $value }}%"

      # High memory usage
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 85% for more than 5 minutes. Current value: {{ $value }}%"

      # Disk space usage
      - alert: HighDiskUsage
        expr: (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"} * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High disk usage detected"
          description: "Disk usage is above 85% on {{ $labels.device }}. Current value: {{ $value }}%"

      # System load average
      - alert: HighSystemLoad
        expr: node_load15 / count(node_cpu_seconds_total{mode="idle"}) without (cpu, mode) > 1.5
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High system load detected"
          description: "System load average is {{ $value }} for more than 10 minutes"

  # =============================================================================
  # DATABASE ALERTS
  # =============================================================================

  - name: database.rules
    rules:
      # PostgreSQL down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          service: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"

      # High database connections
      - alert: HighDatabaseConnections
        expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High database connection usage"
          description: "Database connection usage is above 80%. Current: {{ $value }}%"

      # Long running queries
      - alert: LongRunningQueries
        expr: pg_stat_activity_max_tx_duration{datname!="template0",datname!="template1",datname!=""} > 300
        for: 2m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Long running database queries detected"
          description: "Database {{ $labels.datname }} has queries running for more than 5 minutes"

      # Database replication lag
      - alert: DatabaseReplicationLag
        expr: pg_stat_replication_lag > 100
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Database replication lag detected"
          description: "PostgreSQL replication lag is {{ $value }} MB"

      # Database deadlocks
      - alert: DatabaseDeadlocks
        expr: increase(pg_stat_database_deadlocks[5m]) > 5
        for: 1m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Database deadlocks detected"
          description: "{{ $value }} deadlocks detected in the last 5 minutes on database {{ $labels.datname }}"

  # =============================================================================
  # CACHE ALERTS
  # =============================================================================

  - name: cache.rules
    rules:
      # Redis down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          service: cache
        annotations:
          summary: "Redis is down"
          description: "Redis instance {{ $labels.instance }} is down"

      # High Redis memory usage
      - alert: HighRedisMemoryUsage
        expr: redis_memory_used_bytes / redis_config_maxmemory * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "High Redis memory usage"
          description: "Redis memory usage is above 90%. Current: {{ $value }}%"

      # Redis replication broken
      - alert: RedisReplicationBroken
        expr: redis_connected_slaves == 0
        for: 5m
        labels:
          severity: critical
          service: cache
        annotations:
          summary: "Redis replication is broken"
          description: "Redis master has no connected slaves"

      # High Redis client connections
      - alert: HighRedisConnections
        expr: redis_connected_clients > 100
        for: 5m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "High Redis client connections"
          description: "Redis has {{ $value }} connected clients"

  # =============================================================================
  # APPLICATION ALERTS
  # =============================================================================

  - name: application.rules
    rules:
      # Application down
      - alert: ApplicationDown
        expr: up{job=~"smartattend-.*"} == 0
        for: 2m
        labels:
          severity: critical
          service: application
        annotations:
          summary: "Application instance is down"
          description: "{{ $labels.job }} service {{ $labels.instance }} is down"

      # High HTTP error rate
      - alert: HighHTTPErrorRate
        expr: rate(nginx_http_requests_total{status=~"5.."}[5m]) / rate(nginx_http_requests_total[5m]) * 100 > 5
        for: 5m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High HTTP 5xx error rate"
          description: "HTTP 5xx error rate is {{ $value }}% for more than 5 minutes"

      # High response time
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(nginx_http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for more than 5 minutes"

      # Celery queue backed up
      - alert: CeleryQueueBackedUp
        expr: celery_queue_length > 1000
        for: 10m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "Celery queue is backed up"
          description: "Celery queue has {{ $value }} pending tasks"

      # Too many failed tasks
      - alert: HighCeleryFailureRate
        expr: rate(celery_task_failed_total[5m]) / rate(celery_task_total[5m]) * 100 > 10
        for: 5m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High Celery task failure rate"
          description: "Celery task failure rate is {{ $value }}% for more than 5 minutes"

  # =============================================================================
  # BUSINESS LOGIC ALERTS
  # =============================================================================

  - name: business.rules
    rules:
      # Low user activity
      - alert: LowUserActivity
        expr: rate(smartattend_user_logins_total[1h]) < 10
        for: 30m
        labels:
          severity: warning
          service: business
        annotations:
          summary: "Low user activity detected"
          description: "User login rate is {{ $value }} per hour for the last 30 minutes"

      # High authentication failures
      - alert: HighAuthenticationFailures
        expr: rate(smartattend_auth_failures_total[5m]) > 5
        for: 5m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "High authentication failure rate"
          description: "Authentication failure rate is {{ $value }} per minute"

      # Database backup failed
      - alert: DatabaseBackupFailed
        expr: time() - smartattend_last_backup_timestamp > 86400
        for: 1m
        labels:
          severity: critical
          service: backup
        annotations:
          summary: "Database backup failed"
          description: "Last successful backup was {{ $value }} seconds ago"

  # =============================================================================
  # INFRASTRUCTURE ALERTS
  # =============================================================================

  - name: infrastructure.rules
    rules:
      # SSL certificate expiring
      - alert: SSLCertificateExpiring
        expr: probe_ssl_earliest_cert_expiry - time() < 604800
        for: 1m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "SSL certificate expiring soon"
          description: "SSL certificate for {{ $labels.instance }} expires in {{ $value | humanizeDuration }}"

      # Website down
      - alert: WebsiteDown
        expr: probe_success{job="blackbox-http"} == 0
        for: 2m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Website is down"
          description: "{{ $labels.instance }} is not responding to HTTP requests"

      # High network latency
      - alert: HighNetworkLatency
        expr: probe_duration_seconds{job="blackbox-http"} > 5
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High network latency detected"
          description: "Network latency to {{ $labels.instance }} is {{ $value }}s"

      # Enhanced service monitoring
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} on {{ $labels.instance }} has been down for more than 1 minute."
          runbook_url: "https://docs.smartattend.com/runbooks/service-down"
          dashboard_url: "http://grafana:3000/d/services"

      # Container health monitoring
      - alert: ContainerRestarting
        expr: increase(container_restart_count[1h]) > 3
        for: 0m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "Container restarting frequently"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last hour."
